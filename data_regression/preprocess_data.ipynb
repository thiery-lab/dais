{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# This script downloads the datasets used for the analysis of the paper\n",
    "# and transforms the continuous covariates with the minimum description length (MDL) method\n",
    "# of Fayyad and Irani (1993).\n",
    "# The datasets are then saved as `.npz` files.\n",
    "####################################################################################################\n",
    "import urllib.request\n",
    "import IPython.core.magics.execution as IPy_exec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects.packages as rpackages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the R package for discretization.\n",
    "utils = rpackages.importr(\"utils\")\n",
    "\n",
    "if not rpackages.isinstalled(\"discretization\"):\n",
    "    utils.install_packages(\n",
    "        \"discretization\", repos=\"https://cloud.r-project.org\"\n",
    "    )\n",
    "\n",
    "discretization = rpackages.importr(\"discretization\")\n",
    "rpy2.robjects.numpy2ri.activate() # Enable passing NumPy arrays to R.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset to load\n",
    "data_sets = dict(\n",
    "    spam=dict(url=\"spambase/spambase\"),\n",
    "    krkp=dict(url=\"chess/king-rook-vs-king-pawn/kr-vs-kp\"),\n",
    "    ionosphere=dict(url=\"ionosphere/ionosphere\"),\n",
    "    mushroom=dict(url=\"mushroom/agaricus-lepiota\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing the spam data...\n",
      "\t Loading the data set...\n",
      "\t The data set has 4601 rows and 58 columns.\n",
      "\t Discretizing the data...\n",
      "\t Discretization completed.\n",
      "\t Number of covariates: 105\n"
     ]
    }
   ],
   "source": [
    "for data_name in data_sets.keys():\n",
    "    print(\"\\nProcessing the\", data_name, \"data...\")\n",
    "    # Load the data set\n",
    "    print(\"\\t Loading the data set...\")\n",
    "    url_base = \"https://archive.ics.uci.edu/ml/machine-learning-databases/\"\n",
    "    url = url_base + data_sets[data_name][\"url\"] + \".data\"\n",
    "    tmp = np.genfromtxt(urllib.request.urlopen(url), dtype=str, delimiter=\",\")\n",
    "    print(\"\\t The data set has\", tmp.shape[0], \"rows and\", tmp.shape[1], \"columns.\")\n",
    "    \n",
    "    # preprocess the data\n",
    "    print(\"\\t Discretizing the data...\")\n",
    "    if data_name == \"spam\":\n",
    "        y = tmp[:, -1] == \"0\"\n",
    "        tmp = tmp[:, :-1].astype(float)\n",
    "        tmp = np.asarray(discretization.mdlp(np.hstack((tmp, y[:, np.newaxis])))[1])[:, :-1].astype(int)\n",
    "    elif data_name == \"krkp\":\n",
    "        y = tmp[:, -1] == \"won\"\n",
    "        tmp = tmp[:, :-1]\n",
    "    elif data_name == \"ionosphere\":\n",
    "        y = tmp[:, -1] == \"g\"\n",
    "        tmp = tmp[:, :-1].astype(float)\n",
    "        tmp = np.hstack((\n",
    "            tmp[:, :2], # The first two columns are already discretized.\n",
    "            np.asarray(discretization.mdlp(np.hstack((tmp[:, 2:], y[:, np.newaxis])))[1])[:, :-1])).astype(int)\n",
    "    elif data_name == \"mushroom\":\n",
    "        y = tmp[:, 0] == \"e\"\n",
    "        tmp = tmp[:, 1:]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown data set.\")\n",
    "    \n",
    "    print(\"\\t Discretization completed.\")\n",
    "    \n",
    "    # Transform y to a jax.numpy.array of -1s and 1s.\n",
    "    y = np.asarray(2*y - 1)\n",
    "    dim = tmp.shape[1]\n",
    "    \n",
    "    # Ensure that the first category is the most common for dummy variable\n",
    "    # encoding.\n",
    "    for j in range(dim):\n",
    "        counts = np.unique(tmp[:, j], return_counts=True)\n",
    "        tmp[tmp[:, j] == counts[0][np.argmax(counts[1])], j] = 0\n",
    "    \n",
    "    dummies = [pd.get_dummies(tmp[:, j], drop_first=True).values for j in range(dim)]\n",
    "    X = np.hstack(dummies)\n",
    "\n",
    "    # add intercept to X\n",
    "    n = len(y)\n",
    "    X = np.hstack((np.ones((n, 1)), X))\n",
    "\n",
    "\n",
    "    dim_final = X.shape[1]\n",
    "    print(\"\\t Number of covariates:\", dim_final)\n",
    "    \n",
    "    # create a dictionary with the data\n",
    "    regression_data = dict(X=X, y=y)\n",
    "    \n",
    "    # save the data to disk in numpy format\n",
    "    save_file = data_name + \".npz\"\n",
    "    # save the data\n",
    "    np.savez(save_file, **regression_data)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the spam data...\n",
      "The data set has 4601 rows and 105 columns.\n",
      "\n",
      "Loading the krkp data...\n",
      "The data set has 3196 rows and 38 columns.\n",
      "\n",
      "Loading the ionosphere data...\n",
      "The data set has 351 rows and 111 columns.\n",
      "\n",
      "Loading the mushroom data...\n",
      "The data set has 8124 rows and 96 columns.\n"
     ]
    }
   ],
   "source": [
    "# sanity check: load the data and check the shapes\n",
    "for data_name in data_sets.keys():\n",
    "    print(\"\\nLoading the\", data_name, \"data...\")\n",
    "    # Load the data set\n",
    "    save_file = data_name + \".npz\"\n",
    "    regression_data = np.load(save_file)\n",
    "    X = regression_data[\"X\"]\n",
    "    y = regression_data[\"y\"]\n",
    "    print(\"The data set has\", X.shape[0], \"rows and\", X.shape[1], \"columns.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
